{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF Data:\n",
      "                 Feature        VIF\n",
      "0           Customer_Age  75.872049\n",
      "3         Months_on_book  56.943713\n",
      "7           Credit_Limit        inf\n",
      "8    Total_Revolving_Bal        inf\n",
      "9        Avg_Open_To_Buy        inf\n",
      "10  Total_Amt_Chng_Q4_Q1  13.694302\n",
      "12        Total_Trans_Ct  22.857143\n",
      "13   Total_Ct_Chng_Q4_Q1  11.786845\n",
      "Accuracy: 0.9012\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1205\n",
      "           1       0.73      0.54      0.62       212\n",
      "\n",
      "    accuracy                           0.90      1417\n",
      "   macro avg       0.83      0.75      0.78      1417\n",
      "weighted avg       0.89      0.90      0.90      1417\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1162   43]\n",
      " [  97  115]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('BankChurners.csv')\n",
    "\n",
    "# Preprocess data\n",
    "data_cleaned = data.drop(columns=['CLIENTNUM', 'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1', \n",
    "                                  'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'])\n",
    "\n",
    "# Drop rows with 'Unknown' values\n",
    "data_cleaned = data_cleaned[~data_cleaned['Education_Level'].isin(['Unknown'])]\n",
    "data_cleaned = data_cleaned[~data_cleaned['Income_Category'].isin(['Unknown'])]\n",
    "data_cleaned = data_cleaned[~data_cleaned['Marital_Status'].isin(['Unknown'])]\n",
    "\n",
    "# Convert 'Gender' to numeric (M -> 1, F -> 0)\n",
    "data_cleaned['Gender'] = data_cleaned['Gender'].map({'M': 1, 'F': 0})\n",
    "\n",
    "# Convert 'Attrition_Flag' to binary target variable 'Churn'\n",
    "data_cleaned['Churn'] = data_cleaned['Attrition_Flag'].apply(lambda x: 1 if x == 'Attrited Customer' else 0)\n",
    "\n",
    "# Drop the 'Attrition_Flag' column as we now have 'Churn'\n",
    "data_cleaned = data_cleaned.drop(columns=['Attrition_Flag'])\n",
    "\n",
    "# Binning 'Customer_Age' into Age Group\n",
    "age_bins = [18, 30, 50, 100]\n",
    "age_labels = ['Young', 'Middle-Aged', 'Senior']\n",
    "data_cleaned['Age_Group'] = pd.cut(data_cleaned['Customer_Age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Create additional features: Avg_Open_To_Buy and Avg_Utilization_Ratio\n",
    "data_cleaned['Avg_Open_To_Buy'] = data_cleaned['Credit_Limit'] - data_cleaned['Total_Revolving_Bal']\n",
    "data_cleaned['Avg_Utilization_Ratio'] = data_cleaned['Total_Revolving_Bal'] / data_cleaned['Credit_Limit']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "data_cleaned_encoded = pd.get_dummies(data_cleaned, drop_first=True)\n",
    "\n",
    "# VIF Calculation\n",
    "numerical_cols = data_cleaned_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "X = data_cleaned_encoded[numerical_cols].drop(columns=['Churn'])\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "print(\"VIF Data:\")\n",
    "print(vif_data[vif_data['VIF'] > 10])  # High VIF\n",
    "\n",
    "# Drop collinear features based on VIF\n",
    "data_cleaned_encoded_reduced = data_cleaned_encoded.drop(columns=['Credit_Limit', 'Total_Revolving_Bal', 'Avg_Open_To_Buy'])\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_cleaned_encoded_reduced.drop(columns=['Churn']), data_cleaned_encoded_reduced['Churn'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions and Evaluation\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Becode-son\\AppData\\Local\\Temp\\ipykernel_11532\\1358855752.py:20: DeprecationWarning: numpy.core is deprecated and has been renamed to numpy._core. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.arrayprint.\n",
      "  np.core.arrayprint._line_width = 180\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/becode/LearnAI/scikit/scikit/Unsupervised Learning/datasets_14701_19663_CC GENERAL.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m np\u001b[38;5;241m.\u001b[39mset_printoptions(edgeitems\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     20\u001b[0m np\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39marrayprint\u001b[38;5;241m.\u001b[39m_line_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m---> 22\u001b[0m credit \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/becode/LearnAI/scikit/scikit/Unsupervised Learning/datasets_14701_19663_CC GENERAL.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(credit\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(credit\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/becode/LearnAI/scikit/scikit/Unsupervised Learning/datasets_14701_19663_CC GENERAL.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Clustering\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "# Import preprocessing for LabelEncoder en OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "# Import scikit-learn metrics module\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Display options dataframes\n",
    "pd.set_option('display.width',400)\n",
    "pd.set_option('display.max_columns', 40)\n",
    "# Display options numpy arrays\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.core.arrayprint._line_width = 180\n",
    "\n",
    "credit = pd.read_csv(\"/home/becode/LearnAI/scikit/scikit/Unsupervised Learning/datasets_14701_19663_CC GENERAL.csv\")\n",
    "print(credit.head(10))\n",
    "print(credit.shape)\n",
    "print(credit.describe())\n",
    "print(credit.info())\n",
    "print(credit.isna().sum())\n",
    "# replace NA's in MINIMUM_PAYMENTS and CREDIT_LIMIT, respectively 10 and 1 NA's and check afterwards\n",
    "credit.MINIMUM_PAYMENTS.fillna(credit.MINIMUM_PAYMENTS.mean(), inplace=True)\n",
    "credit.CREDIT_LIMIT.fillna(credit.CREDIT_LIMIT.mean(),inplace=True)\n",
    "print(credit.isna().sum())\n",
    "\n",
    "# Customer ID is irrelevant for clustering users\n",
    "credit = credit.drop('CUST_ID', axis =1)\n",
    "\n",
    "# print correlation heat map (Pearson's coeff)\n",
    "\"\"\"\n",
    "corr=credit.corr()\n",
    "top_features=corr.index\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(credit[top_features].corr(),annot=True)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# Look at data spread\n",
    "sns.boxplot(data=credit)\n",
    "plt.show()\n",
    "\n",
    "# Standardizing the data\n",
    "X = credit # or X = np.asarray(credit)\n",
    "stan = preprocessing.StandardScaler()\n",
    "X = stan.fit_transform(X)\n",
    "\n",
    "\"\"\"\n",
    "# Elbow curve : inertia vs k\n",
    "n_clusters=20\n",
    "cost=[]\n",
    "for i in range(1,n_clusters):\n",
    "    kmeans= KMeans(i)\n",
    "    kmeans.fit(X)\n",
    "    cost.append(kmeans.inertia_)\n",
    "plt.plot(range(1,20),cost)\n",
    "plt.xticks(range(1,20,2))\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# Silhouette curve : Silhouette vs k\n",
    "\"\"\"\n",
    "The silhouette coefficient can vary between -1 and +1: a coefficient close to +1 means that the instance is well \n",
    "inside its own cluster and far from other clusters, while a coefficient close to 0 means that it is close to a \n",
    "cluster boundary, and finally a coefficient close to -1 means that the instance may have been assigned to the wrong\n",
    "cluster.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "n_clusters=20\n",
    "sil_scores=[]\n",
    "for i in range(2,n_clusters):  # n_clusters can not be 1, took me a really long time to change the range from range(1, n) tp (2,n)\n",
    "    kmeans = KMeans(i)\n",
    "    labels = kmeans.fit_predict(X) # or kmeans.labels_ is the same\n",
    "    sil_scores.append(silhouette_score(X,labels))\n",
    "plt.plot(range(2,20),sil_scores)\n",
    "plt.title('The Silhouette curve')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette')\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# Silhouette scores highest for k=3 but only marginal differnce, the score is too close to 0, 1 means good clustering\n",
    "\n",
    "# Call KMeans and calculate silhouette score, can't calculate adjsuetd rand 'cause I don't have an actual y)\n",
    "# Only 3 clusters\n",
    "kmeans = KMeans(n_clusters=3, init='k-means++',n_init=10, max_iter=300, random_state=123 )\n",
    "kmeans.fit_predict(X)\n",
    "print(f\"silhouette score = {silhouette_score(X,kmeans.labels_)}\")\n",
    "# I think I really need to take a look at the data and reorganize it, arrange the outliers !\n",
    "\n",
    "# Facetgrid Plots per clusters:\n",
    "\"\"\"\n",
    "clusters = credit\n",
    "clusters['Clusters'] = kmeans.labels_  # add column with cluster labels to a copy of our dataframe\n",
    "print(clusters.head(10))\n",
    "i=0\n",
    "fig1 = plt.figure()\n",
    "## number of co??\n",
    "for column in clusters:\n",
    "    i += 1\n",
    "    grid = sns.FacetGrid(clusters, col='Clusters')\n",
    "    grid.map(plt.hist,column)\n",
    "    ax = fig1.add_subplot(len(clusters.columns.tolist()),1, i)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# PCA to visualize clusters, my clustering is poor\n",
    "dist = 1 - cosine_similarity(X)\n",
    "\n",
    "pca = PCA(2)\n",
    "pca.fit(dist)\n",
    "X_PCA = pca.transform(dist)\n",
    "print(X_PCA.shape)\n",
    "x, y = X_PCA[:, 0], X_PCA[:, 1]\n",
    "\n",
    "labels = kmeans.labels_\n",
    "\n",
    "colors = {0: 'red',\n",
    "          1: 'blue',\n",
    "          2: 'green'}\n",
    "\n",
    "names = {0: 'who make all type of purchases',\n",
    "         1: 'more people with due payments',\n",
    "         2: 'who purchases mostly in installments'}\n",
    "\n",
    "df = pd.DataFrame({'x': x, 'y': y, 'label': labels})\n",
    "groups = df.groupby('label')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 13))\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=5,\n",
    "            color=colors[name], label=names[name], mec='none')\n",
    "    ax.set_aspect('auto')\n",
    "    ax.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off')\n",
    "    ax.tick_params(axis='y', which='both', left='off', top='off', labelleft='off')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"Customers Segmentation based on their Credit Card usage bhaviour.\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "columns = ['BALANCE', 'PURCHASES', 'ONEOFF_PURCHASES', 'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT',\n",
    "           'PAYMENTS', 'MINIMUM_PAYMENTS']\n",
    "\n",
    "for c in columns:\n",
    "    Range = c + '_RANGE'\n",
    "    data[Range] = 0\n",
    "    data.loc[((data[c] > 0) & (data[c] <= 500)), Range] = 1\n",
    "    data.loc[((data[c] > 500) & (data[c] <= 1000)), Range] = 2\n",
    "    data.loc[((data[c] > 1000) & (data[c] <= 3000)), Range] = 3\n",
    "    data.loc[((data[c] > 3000) & (data[c] <= 5000)), Range] = 4\n",
    "    data.loc[((data[c] > 5000) & (data[c] <= 10000)), Range] = 5\n",
    "    data.loc[((data[c] > 10000)), Range] = 6\n",
    "\n",
    "columns = ['BALANCE_FREQUENCY', 'PURCHASES_FREQUENCY', 'ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY',\n",
    "           'CASH_ADVANCE_FREQUENCY', 'PRC_FULL_PAYMENT']\n",
    "\n",
    "for c in columns:\n",
    "    Range = c + '_RANGE'\n",
    "    data[Range] = 0\n",
    "    data.loc[((data[c] > 0) & (data[c] <= 0.1)), Range] = 1\n",
    "    data.loc[((data[c] > 0.1) & (data[c] <= 0.2)), Range] = 2\n",
    "    data.loc[((data[c] > 0.2) & (data[c] <= 0.3)), Range] = 3\n",
    "    data.loc[((data[c] > 0.3) & (data[c] <= 0.4)), Range] = 4\n",
    "    data.loc[((data[c] > 0.4) & (data[c] <= 0.5)), Range] = 5\n",
    "    data.loc[((data[c] > 0.5) & (data[c] <= 0.6)), Range] = 6\n",
    "    data.loc[((data[c] > 0.6) & (data[c] <= 0.7)), Range] = 7\n",
    "    data.loc[((data[c] > 0.7) & (data[c] <= 0.8)), Range] = 8\n",
    "    data.loc[((data[c] > 0.8) & (data[c] <= 0.9)), Range] = 9\n",
    "    data.loc[((data[c] > 0.9) & (data[c] <= 1.0)), Range] = 10\n",
    "\n",
    "columns = ['PURCHASES_TRX', 'CASH_ADVANCE_TRX']\n",
    "\n",
    "for c in columns:\n",
    "    Range = c + '_RANGE'\n",
    "    data[Range] = 0\n",
    "    data.loc[((data[c] > 0) & (data[c] <= 5)), Range] = 1\n",
    "    data.loc[((data[c] > 5) & (data[c] <= 10)), Range] = 2\n",
    "    data.loc[((data[c] > 10) & (data[c] <= 15)), Range] = 3\n",
    "    data.loc[((data[c] > 15) & (data[c] <= 20)), Range] = 4\n",
    "    data.loc[((data[c] > 20) & (data[c] <= 30)), Range] = 5\n",
    "    data.loc[((data[c] > 30) & (data[c] <= 50)), Range] = 6\n",
    "    data.loc[((data[c] > 50) & (data[c] <= 100)), Range] = 7\n",
    "    data.loc[((data[c] > 100)), Range] = 8\n",
    "\"\"\"\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# silhouette_score(X, kmeans.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
