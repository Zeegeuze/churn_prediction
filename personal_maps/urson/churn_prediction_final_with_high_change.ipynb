{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3028932",
   "metadata": {},
   "source": [
    "# **Churn Prediction: Final Refined Version**\n",
    "This notebook implements data preprocessing, thorough EDA, and model evaluation for churn prediction using Random Forest and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d782f",
   "metadata": {},
   "source": [
    "## **Step 1: Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e5dc841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c76565",
   "metadata": {},
   "source": [
    "## **Step 2: Load and Inspect Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b029f0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Feature Set: Index(['Attrition_Flag', 'Customer_Age', 'Gender', 'Dependent_count',\n",
      "       'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category',\n",
      "       'Months_on_book', 'Total_Relationship_Count', 'Months_Inactive_12_mon',\n",
      "       'Contacts_Count_12_mon', 'Credit_Limit', 'Total_Revolving_Bal',\n",
      "       'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt', 'Total_Trans_Ct',\n",
      "       'Total_Ct_Chng_Q4_Q1', 'Avg_Utilization_Ratio'],\n",
      "      dtype='object')\n",
      "Data Overview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Single</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Existing Customer</td>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Attrition_Flag  Customer_Age Gender  Dependent_count Education_Level  \\\n",
       "0  Existing Customer            45      M                3     High School   \n",
       "1  Existing Customer            49      F                5        Graduate   \n",
       "2  Existing Customer            51      M                3        Graduate   \n",
       "3  Existing Customer            40      F                4     High School   \n",
       "4  Existing Customer            40      M                3      Uneducated   \n",
       "\n",
       "  Marital_Status Income_Category Card_Category  Months_on_book  \\\n",
       "0        Married     $60K - $80K          Blue              39   \n",
       "1         Single  Less than $40K          Blue              44   \n",
       "2        Married    $80K - $120K          Blue              36   \n",
       "3        Unknown  Less than $40K          Blue              34   \n",
       "4        Married     $60K - $80K          Blue              21   \n",
       "\n",
       "   Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                         5                       1                      3   \n",
       "1                         6                       1                      2   \n",
       "2                         4                       1                      0   \n",
       "3                         3                       4                      1   \n",
       "4                         5                       1                      0   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  \\\n",
       "0       12691.0                  777                 1.335             1144   \n",
       "1        8256.0                  864                 1.541             1291   \n",
       "2        3418.0                    0                 2.594             1887   \n",
       "3        3313.0                 2517                 1.405             1171   \n",
       "4        4716.0                    0                 2.175              816   \n",
       "\n",
       "   Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  \n",
       "0              42                1.625                  0.061  \n",
       "1              33                3.714                  0.105  \n",
       "2              20                2.333                  0.000  \n",
       "3              20                2.333                  0.760  \n",
       "4              28                2.500                  0.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (10127, 19)\n",
      "Null Values:\n",
      "Attrition_Flag              0\n",
      "Customer_Age                0\n",
      "Gender                      0\n",
      "Dependent_count             0\n",
      "Education_Level             0\n",
      "Marital_Status              0\n",
      "Income_Category             0\n",
      "Card_Category               0\n",
      "Months_on_book              0\n",
      "Total_Relationship_Count    0\n",
      "Months_Inactive_12_mon      0\n",
      "Contacts_Count_12_mon       0\n",
      "Credit_Limit                0\n",
      "Total_Revolving_Bal         0\n",
      "Total_Amt_Chng_Q4_Q1        0\n",
      "Total_Trans_Amt             0\n",
      "Total_Trans_Ct              0\n",
      "Total_Ct_Chng_Q4_Q1         0\n",
      "Avg_Utilization_Ratio       0\n",
      "dtype: int64\n",
      "Cleaned Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Becode-son\\AppData\\Local\\Temp\\ipykernel_15256\\204309006.py:25: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Attrition_Flag'] = data['Attrition_Flag'].replace({'Attrited Customer': 1, 'Existing Customer': 0})\n",
      "C:\\Users\\Becode-son\\AppData\\Local\\Temp\\ipykernel_15256\\204309006.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['Gender'] = data['Gender'].replace({'F': 1, 'M': 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>...</th>\n",
       "      <th>Income_Category_$60K - $80K</th>\n",
       "      <th>Income_Category_$80K - $120K</th>\n",
       "      <th>Income_Category_Less than $40K</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Card_Category_Blue</th>\n",
       "      <th>Card_Category_Gold</th>\n",
       "      <th>Card_Category_Platinum</th>\n",
       "      <th>Card_Category_Silver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attrition_Flag  Customer_Age  Gender  Dependent_count  Months_on_book  \\\n",
       "0               0            45       0                3              39   \n",
       "1               0            49       1                5              44   \n",
       "2               0            51       0                3              36   \n",
       "3               0            40       1                4              34   \n",
       "4               0            40       0                3              21   \n",
       "\n",
       "   Total_Relationship_Count  Months_Inactive_12_mon  Contacts_Count_12_mon  \\\n",
       "0                         5                       1                      3   \n",
       "1                         6                       1                      2   \n",
       "2                         4                       1                      0   \n",
       "3                         3                       4                      1   \n",
       "4                         5                       1                      0   \n",
       "\n",
       "   Credit_Limit  Total_Revolving_Bal  ...  Income_Category_$60K - $80K  \\\n",
       "0       12691.0                  777  ...                         True   \n",
       "1        8256.0                  864  ...                        False   \n",
       "2        3418.0                    0  ...                        False   \n",
       "3        3313.0                 2517  ...                        False   \n",
       "4        4716.0                    0  ...                         True   \n",
       "\n",
       "   Income_Category_$80K - $120K  Income_Category_Less than $40K  \\\n",
       "0                         False                           False   \n",
       "1                         False                            True   \n",
       "2                          True                           False   \n",
       "3                         False                            True   \n",
       "4                         False                           False   \n",
       "\n",
       "   Marital_Status_Divorced  Marital_Status_Married  Marital_Status_Single  \\\n",
       "0                    False                    True                  False   \n",
       "1                    False                   False                   True   \n",
       "2                    False                    True                  False   \n",
       "3                    False                   False                  False   \n",
       "4                    False                    True                  False   \n",
       "\n",
       "   Card_Category_Blue  Card_Category_Gold  Card_Category_Platinum  \\\n",
       "0                True               False                   False   \n",
       "1                True               False                   False   \n",
       "2                True               False                   False   \n",
       "3                True               False                   False   \n",
       "4                True               False                   False   \n",
       "\n",
       "   Card_Category_Silver  \n",
       "0                 False  \n",
       "1                 False  \n",
       "2                 False  \n",
       "3                 False  \n",
       "4                 False  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Shape: (10127, 33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('BankChurners.csv')\n",
    "\n",
    "# Drop CLIENTNUM and Naive Bayes classifier columns\n",
    "data.drop(columns=['CLIENTNUM', \n",
    "                   'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "                   'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',\n",
    "                   'Avg_Open_To_Buy'],\n",
    "          inplace=True)\n",
    "\n",
    "# Confirm updated features\n",
    "print(\"Updated Feature Set:\", data.columns)\n",
    "\n",
    "# Overview\n",
    "print(\"Data Overview:\")\n",
    "display(data.head())\n",
    "print(\"Shape of data:\", data.shape)\n",
    "print(\"Null Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "# Encode target variable and binary features\n",
    "data['Attrition_Flag'] = data['Attrition_Flag'].replace({'Attrited Customer': 1, 'Existing Customer': 0})\n",
    "data['Gender'] = data['Gender'].replace({'F': 1, 'M': 0})\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_cols = ['Education_Level', 'Income_Category', 'Marital_Status', 'Card_Category']\n",
    "for col in categorical_cols:\n",
    "    if 'Unknown' in data[col].unique():\n",
    "        data = pd.concat([data, pd.get_dummies(data[col], prefix=col).drop(columns='{}_Unknown'.format(col))], axis=1)\n",
    "    else:\n",
    "        data = pd.concat([data, pd.get_dummies(data[col], prefix=col)], axis=1)\n",
    "\n",
    "# Drop original categorical columns\n",
    "data.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "print(\"Cleaned Data:\")\n",
    "display(data.head())\n",
    "print(\"Updated Shape:\", data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413fc3f5",
   "metadata": {},
   "source": [
    "## **Step 3: Encode Categorical Columns and Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5505f96e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Education_Level'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Education_Level'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m categorical_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEducation_Level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncome_Category\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarital_Status\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCard_Category\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m      9\u001b[0m         data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([data, pd\u001b[38;5;241m.\u001b[39mget_dummies(data[col], prefix\u001b[38;5;241m=\u001b[39mcol)\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_Unknown\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(col))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Becode-son\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Education_Level'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode target variable and binary features\n",
    "data['Attrition_Flag'] = data['Attrition_Flag'].replace({'Attrited Customer': 1, 'Existing Customer': 0})\n",
    "data['Gender'] = data['Gender'].replace({'F': 1, 'M': 0})\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_cols = ['Education_Level', 'Income_Category', 'Marital_Status', 'Card_Category']\n",
    "for col in categorical_cols:\n",
    "    if 'Unknown' in data[col].unique():\n",
    "        data = pd.concat([data, pd.get_dummies(data[col], prefix=col).drop(columns='{}_Unknown'.format(col))], axis=1)\n",
    "    else:\n",
    "        data = pd.concat([data, pd.get_dummies(data[col], prefix=col)], axis=1)\n",
    "\n",
    "# Drop original categorical columns\n",
    "data.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "print(\"Cleaned Data:\")\n",
    "display(data.head())\n",
    "print(\"Updated Shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03928511",
   "metadata": {},
   "source": [
    "## **Step 4: Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize class imbalance\n",
    "sns.countplot(x='Attrition_Flag', data=data)\n",
    "plt.title(\"Churn Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for numerical features to identify patterns\n",
    "numerical_features = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numerical_features, 1):\n",
    "    plt.subplot(4, 4, i)\n",
    "    sns.boxplot(y=data[col], x=data['Attrition_Flag'])\n",
    "    plt.title(f\"{col} by Churn\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot for Total_Trans_Ct vs Total_Trans_Amt\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Total_Trans_Ct', y='Total_Trans_Amt', data=data)\n",
    "plt.title('Relationship Between Transaction Count and Amount')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27af97",
   "metadata": {},
   "source": [
    "## **Step 5: Train-Test Split and Class Balancing with SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c26a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split data\n",
    "X = data.drop(columns=['Attrition_Flag'])\n",
    "y = data['Attrition_Flag']\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# SMOTE for imbalance handling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class Distribution After SMOTE:\")\n",
    "print(y_train_res.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f6243",
   "metadata": {},
   "source": [
    "## **Step 6: Random Forest Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e8d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_rf):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_rf):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_rf):.2f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fade5e",
   "metadata": {},
   "source": [
    "## **Step 7: XGBoost Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c593cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xgb_model = XGBClassifier(scale_pos_weight=6, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.2f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_xgb):.2f}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_xgb):.2f}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_xgb):.2f}\")\n",
    "print(\"Classification Report:\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca05d23",
   "metadata": {},
   "source": [
    "## **Step 8: Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eea1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "importances = xgb_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(10))\n",
    "plt.title(\"Top 10 Feature Importances\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fda00",
   "metadata": {},
   "source": [
    "## **Step 9: Feature Redundancy Test**\n",
    "In this section, we evaluate whether `Total_Trans_Amt` can be safely dropped without significantly impacting the model performance. This is done by training and comparing the XGBoost model with and without the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd47f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Redefine features and target variable to avoid earlier modifications\n",
    "X = data.drop(columns=['Attrition_Flag'])  # All features\n",
    "y = data['Attrition_Flag']                # Target variable\n",
    "\n",
    "# Section: Evaluating Redundant Features (Total_Trans_Ct vs Total_Trans_Amt)\n",
    "\n",
    "# 1. Train model with both features\n",
    "X_full = X.copy()  # Original features\n",
    "y_full = y.copy()\n",
    "\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y_full, test_size=0.3, random_state=42, stratify=y_full)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res_full, y_train_res_full = smote.fit_resample(X_train_full, y_train_full)\n",
    "\n",
    "# Train XGBoost with both features\n",
    "xgb_full = XGBClassifier(scale_pos_weight=6, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "xgb_full.fit(X_train_res_full, y_train_res_full)\n",
    "y_pred_full = xgb_full.predict(X_test_full)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Model Performance with Both Features:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_full, y_pred_full):.2f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test_full, y_pred_full):.2f}\")\n",
    "\n",
    "# 2. Train model without Total_Trans_Amt\n",
    "X_reduced = X.drop(columns=['Total_Trans_Amt'])  # Drop redundant feature\n",
    "\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_reduced, y_full, test_size=0.3, random_state=42, stratify=y_full)\n",
    "\n",
    "# Handle class imbalance\n",
    "X_train_res_red, y_train_res_red = smote.fit_resample(X_train_red, y_train_red)\n",
    "\n",
    "# Train XGBoost without Total_Trans_Amt\n",
    "xgb_red = XGBClassifier(scale_pos_weight=6, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "xgb_red.fit(X_train_res_red, y_train_res_red)\n",
    "y_pred_red = xgb_red.predict(X_test_red)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nModel Performance Without Total_Trans_Amt:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_red, y_pred_red):.2f}\")\n",
    "print(f\"F1-Score: {f1_score(y_test_red, y_pred_red):.2f}\")\n",
    "\n",
    "# 3. Compare results\n",
    "print(\"\\nComparison of Model Performance:\")\n",
    "print(f\"Accuracy Difference: {accuracy_score(y_test_full, y_pred_full) - accuracy_score(y_test_red, y_pred_red):.4f}\")\n",
    "print(f\"F1-Score Difference: {f1_score(y_test_full, y_pred_full) - f1_score(y_test_red, y_pred_red):.4f}\")\n",
    "# Print the confusion matrix for both models\n",
    "print(\"Confusion Matrix with Both Features:\")\n",
    "print(confusion_matrix(y_test_full, y_pred_full))\n",
    "\n",
    "print(\"\\nConfusion Matrix without Total_Trans_Amt:\")\n",
    "print(confusion_matrix(y_test_red, y_pred_red))\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test_full, y_pred_full), annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix with Both Features')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test_red, y_pred_red), annot=True, fmt='d', cmap='Blues', ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix without Total_Trans_Amt')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Analyze High Change Customers\n",
    "\n",
    "# 1. Calculate Rel_Amt_Change and Rel_Ct_Change if not already present\n",
    "if 'Rel_Amt_Change' not in data.columns or 'Rel_Ct_Change' not in data.columns:\n",
    "    print(\"Creating Rel_Amt_Change and Rel_Ct_Change features...\")\n",
    "    data['Rel_Amt_Change'] = data['Total_Amt_Chng_Q4_Q1'] / (data['Total_Trans_Amt'] + 1)  # Avoid division by zero\n",
    "    data['Rel_Ct_Change'] = data['Total_Ct_Chng_Q4_Q1'] / (data['Total_Trans_Ct'] + 1)\n",
    "\n",
    "# 2. Identify high-change customers\n",
    "high_change_customers = data[\n",
    "    (data['Rel_Amt_Change'] > data['Rel_Amt_Change'].quantile(0.95)) | \n",
    "    (data['Rel_Ct_Change'] > data['Rel_Ct_Change'].quantile(0.95))\n",
    "]\n",
    "\n",
    "# 3. Count churned vs. non-churned customers\n",
    "print(\"High Change Customers Churn Analysis:\")\n",
    "print(high_change_customers['Attrition_Flag'].value_counts())\n",
    "\n",
    "# 4. Visualize High Change Customers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Attrition_Flag', data=high_change_customers, palette='coolwarm')\n",
    "plt.title('Churn Distribution Among High Change Customers')\n",
    "plt.xlabel('Churn Flag (0 = No Churn, 1 = Churned)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df078ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Test Model Performance with High-Change Features\n",
    "\n",
    "# Add Rel_Amt_Change and Rel_Ct_Change to the feature set\n",
    "X_new = data.drop(columns=['Attrition_Flag'])  # Use all current features including new ones\n",
    "y = data['Attrition_Flag']\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Train XGBoost model\n",
    "xgb_model = XGBClassifier(scale_pos_weight=6, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "xgb_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Evaluate model performance\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Performance with High-Change Features:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Evaluate model performance\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Model Performance with High-Change Features:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# Print the Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "# Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b88823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Redundant Features\n",
    "X_reduced = X.drop(columns=['Total_Revolving_Bal'])\n",
    "\n",
    "# Train-Test Split with Reduced Features\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(\n",
    "    X_reduced, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res_red, y_train_res_red = smote.fit_resample(X_train_red, y_train_red)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_reduced = XGBClassifier(\n",
    "    scale_pos_weight=6, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42\n",
    ")\n",
    "xgb_reduced.fit(X_train_res_red, y_train_res_red)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred_red = xgb_reduced.predict(X_test_red)\n",
    "print(\"Performance After Dropping Redundant Features:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_red, y_pred_red))\n",
    "print(\"Recall:\", recall_score(y_test_red, y_pred_red))\n",
    "print(\"F1-Score:\", f1_score(y_test_red, y_pred_red))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_red, xgb_reduced.predict_proba(X_test_red)[:, 1]))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_red, y_pred_red)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "plt.title(\"Confusion Matrix After Dropping Features\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2604c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "\n",
    "# Drop Redundant Features\n",
    "X_reduced = X.drop(columns=['Total_Revolving_Bal']) \n",
    "\n",
    "X_reduced.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ef90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    roc_auc_score, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# Drop Redundant Features\n",
    "\n",
    "# Train-Test Split with Reduced Features\n",
    "X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(\n",
    "    X_reduced, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res_red, y_train_res_red = smote.fit_resample(X_train_red, y_train_red)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_reduced = XGBClassifier(\n",
    "    scale_pos_weight=6, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42\n",
    ")\n",
    "xgb_reduced.fit(X_train_res_red, y_train_res_red)\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred_red = xgb_reduced.predict(X_test_red)\n",
    "print(\"Performance After Dropping Redundant Features:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test_red, y_pred_red))\n",
    "print(\"Recall:\", recall_score(y_test_red, y_pred_red))\n",
    "print(\"F1-Score:\", f1_score(y_test_red, y_pred_red))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_red, xgb_reduced.predict_proba(X_test_red)[:, 1]))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_red, y_pred_red)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "plt.title(\"Confusion Matrix After Dropping Features\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e778008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Prepare the data\n",
    "X = data.drop(columns=['Attrition_Flag'])\n",
    "y = data['Attrition_Flag']\n",
    "\n",
    "# Define Stratified K-Fold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-Validation Function\n",
    "def evaluate_model(model, X, y, model_name):\n",
    "    scores = cross_val_score(model, X, y, cv=skf, scoring='recall')\n",
    "    print(f\"{model_name} Cross-Validation Recall Scores: {scores}\")\n",
    "    print(f\"{model_name} Mean Recall: {scores.mean():.4f}\")\n",
    "\n",
    "# Initialize Models\n",
    "xgb_model = XGBClassifier(scale_pos_weight=6, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# Evaluate Models\n",
    "print(\"Evaluating XGBoost...\")\n",
    "evaluate_model(xgb_model, X, y, \"XGBoost\")\n",
    "\n",
    "print(\"\\nEvaluating Random Forest...\")\n",
    "evaluate_model(rf_model, X, y, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a4b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, recall_score, precision_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Step 2: Load Dataset into New DataFrame\n",
    "data_path = 'BankChurners.csv'  # Replace with actual file path\n",
    "data = pd.read_csv(data_path)\n",
    "print(\"Dataset Loaded Successfully!\")\n",
    "print(f\"Shape: {data.shape}\\n\")\n",
    "print(data.head())\n",
    "\n",
    "# Step 3: Clean and Preprocess Data\n",
    "# Drop client-specific or unnecessary columns\n",
    "data.drop(columns=['CLIENTNUM'], inplace=True)\n",
    "\n",
    "\n",
    "# Encode target variable\n",
    "data['Attrition_Flag'] = data['Attrition_Flag'].replace({'Attrited Customer': 1, 'Existing Customer': 0})\n",
    "\n",
    "# Encode Gender\n",
    "data['Gender'] = data['Gender'].replace({'F': 1, 'M': 0})\n",
    "\n",
    "# One-Hot Encode Categorical Features\n",
    "data = pd.get_dummies(data, columns=['Education_Level', 'Income_Category', 'Marital_Status', 'Card_Category'], drop_first=True)\n",
    "\n",
    "# Step 4: Handle Feature Redundancy\n",
    "# Drop redundant features: Credit_Limit, Avg_Open_To_Buy, and Avg_Utilization_Ratio\n",
    "print(\"Dropping redundant features: ['Credit_Limit', 'Avg_Open_To_Buy', 'Avg_Utilization_Ratio']\")\n",
    "data.drop(columns=['Credit_Limit', 'Avg_Open_To_Buy', 'Avg_Utilization_Ratio'], inplace=True)\n",
    "\n",
    "# Step 5: Feature Engineering - Create Derived Features\n",
    "data['Rel_Amt_Change'] = data['Total_Amt_Chng_Q4_Q1'] / data['Total_Trans_Amt']\n",
    "data['Rel_Ct_Change'] = data['Total_Ct_Chng_Q4_Q1'] / data['Total_Trans_Ct']\n",
    "\n",
    "# Fill any resulting NaN or infinite values\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "print(f\"Updated Data Shape: {data.shape}\\n\")\n",
    "\n",
    "# Step 6: Split Data into Train and Test Sets\n",
    "X = data.drop(columns=['Attrition_Flag'])  # Features\n",
    "y = data['Attrition_Flag']  # Target\n",
    "\n",
    "# Train-Test Split with Stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Handle Class Imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Class Distribution After SMOTE:\")\n",
    "print(y_train_res.value_counts())\n",
    "\n",
    "# Step 7: Model Training and Evaluation Function\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "    print(\"F1-Score:\", f1_score(y_test, y_pred))\n",
    "    if y_pred_proba is not None:\n",
    "        print(\"ROC-AUC:\", roc_auc_score(y_test, y_pred_proba))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Step 8: Train Models\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "train_and_evaluate_model(rf_model, X_train_res, X_test, y_train_res, y_test, \"Random Forest\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = XGBClassifier(scale_pos_weight=6, n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "train_and_evaluate_model(xgb_model, X_train_res, X_test, y_train_res, y_test, \"XGBoost\")\n",
    "\n",
    "# Step 9: Cross-Validation for XGBoost\n",
    "print(\"\\nPerforming Cross-Validation on XGBoost...\")\n",
    "xgb_cv_scores = cross_val_score(xgb_model, X, y, cv=5, scoring='recall')\n",
    "print(\"XGBoost Cross-Validation Recall Scores:\", xgb_cv_scores)\n",
    "print(\"Mean Recall (Cross-Validation):\", np.mean(xgb_cv_scores))\n",
    "\n",
    "# Step 10: High-Change Customer Analysis\n",
    "# Identify High Change Customers\n",
    "high_change_customers = data[\n",
    "    (data['Rel_Amt_Change'] > data['Rel_Amt_Change'].quantile(0.95)) |\n",
    "    (data['Rel_Ct_Change'] > data['Rel_Ct_Change'].quantile(0.95))\n",
    "]\n",
    "\n",
    "print(\"\\nHigh Change Customers Churn Analysis:\")\n",
    "print(high_change_customers['Attrition_Flag'].value_counts())\n",
    "\n",
    "sns.countplot(x='Attrition_Flag', data=high_change_customers, palette='coolwarm')\n",
    "plt.title('High-Change Customers Churn Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nScript Completed Successfully!\")\n",
    "\n",
    "# Feature Importance for Random Forest\n",
    "rf_importances = rf_model.feature_importances_\n",
    "rf_indices = np.argsort(rf_importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Feature Importances - Random Forest\")\n",
    "plt.bar(range(X.shape[1]), rf_importances[rf_indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[rf_indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance for XGBoost\n",
    "xgb_importances = xgb_model.feature_importances_\n",
    "xgb_indices = np.argsort(xgb_importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.title(\"Feature Importances - XGBoost\")\n",
    "plt.bar(range(X.shape[1]), xgb_importances[xgb_indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[xgb_indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
