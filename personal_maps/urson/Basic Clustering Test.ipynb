{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "%pip install pandas numpy matplotlib seaborn scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import DBSCAN\n",
    "data = pd.read_csv('churn_prediction/personal_maps/urson/BankChurners.csv')\n",
    "# Step 2: Load and Clean Dataset\n",
    "\n",
    "# Drop CLIENTNUM, Naive Bayes features, and redundant features\n",
    "data.drop(columns=['CLIENTNUM',\n",
    "                   'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "                   'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2',\n",
    "                   'Avg_Open_To_Buy'],\n",
    "          inplace=True)\n",
    "\n",
    "# Overview\n",
    "print(\"Updated Feature Set:\", data.columns)\n",
    "print(\"Data Overview:\")\n",
    "print(data.head())\n",
    "print(\"Shape of data:\", data.shape)\n",
    "print(\"Null Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Encode target variable and binary features\n",
    "data['Attrition_Flag'] = data['Attrition_Flag'].replace({'Attrited Customer': 1, 'Existing Customer': 0})\n",
    "data['Gender'] = data['Gender'].replace({'F': 1, 'M': 0})\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_cols = ['Education_Level', 'Income_Category', 'Marital_Status', 'Card_Category']\n",
    "for col in categorical_cols:\n",
    "    if 'Unknown' in data[col].unique():\n",
    "        data = pd.concat([data, pd.get_dummies(data[col], prefix=col).drop(columns=f'{col}_Unknown')], axis=1)\n",
    "    else:\n",
    "        data = pd.concat([data, pd.get_dummies(data[col], prefix=col)], axis=1)\n",
    "\n",
    "# Drop original categorical columns\n",
    "data.drop(columns=categorical_cols, inplace=True)\n",
    "\n",
    "# Confirm Cleaned Data\n",
    "print(\"Cleaned Data:\")\n",
    "print(data.head())\n",
    "print(\"Updated Shape:\", data.shape)\n",
    "\n",
    "# Step 3: Scale Numerical Features\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(data.drop(columns=['Attrition_Flag'])), \n",
    "                 columns=data.drop(columns=['Attrition_Flag']).columns)\n",
    "\n",
    "# Step 4: Clustering Methods\n",
    "def clustering_pipeline(model, name, X):\n",
    "    \"\"\" Function to run clustering model and calculate silhouette score \"\"\"\n",
    "    labels = model.fit_predict(X)\n",
    "    silhouette = silhouette_score(X, labels) if len(set(labels)) > 1 else -1\n",
    "    print(f\"{name} Silhouette Score: {silhouette:.2f}\")\n",
    "    return labels\n",
    "\n",
    "# K-Means\n",
    "print(\"\\n--- K-Means Clustering ---\")\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "X['KMeans_Cluster'] = clustering_pipeline(kmeans, \"K-Means\", X)\n",
    "\n",
    "# DBSCAN\n",
    "print(\"\\n--- DBSCAN Clustering ---\")\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=10)\n",
    "X['DBSCAN_Cluster'] = clustering_pipeline(dbscan, \"DBSCAN\", X)\n",
    "\n",
    "# Gaussian Mixture\n",
    "print(\"\\n--- Gaussian Mixture Clustering ---\")\n",
    "gmm = GaussianMixture(n_components=3, random_state=42)\n",
    "X['GMM_Cluster'] = gmm.fit_predict(X)\n",
    "\n",
    "# Agglomerative Clustering\n",
    "print(\"\\n--- Agglomerative Clustering ---\")\n",
    "agglo = AgglomerativeClustering(n_clusters=3)\n",
    "X['Agglo_Cluster'] = clustering_pipeline(agglo, \"Agglomerative\", X)\n",
    "\n",
    "# Step 5: PCA for Visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'GMM_Cluster', 'Agglo_Cluster']))\n",
    "X['PCA1'], X['PCA2'] = X_pca[:, 0], X_pca[:, 1]\n",
    "\n",
    "# Visualization of Clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, cluster in enumerate(['KMeans_Cluster', 'DBSCAN_Cluster', 'GMM_Cluster', 'Agglo_Cluster']):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    sns.scatterplot(x='PCA1', y='PCA2', hue=cluster, data=X, palette='coolwarm', legend='full')\n",
    "    plt.title(f\"{cluster} Clustering\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Post-Clustering Analysis\n",
    "X['Attrition_Flag'] = data['Attrition_Flag'].reset_index(drop=True)\n",
    "\n",
    "for cluster_col in ['KMeans_Cluster', 'DBSCAN_Cluster', 'GMM_Cluster', 'Agglo_Cluster']:\n",
    "    print(f\"\\nChurn Rate by {cluster_col}:\")\n",
    "    print(X.groupby(cluster_col)['Attrition_Flag'].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
