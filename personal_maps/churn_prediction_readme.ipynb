{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Churn Prediction Project - XGBoost and Random Forest Models** (Draft Urson & Anastassia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Overview**\n",
    "This project implements a churn prediction model using **XGBoost** and **Random Forest** classifiers. It includes data preprocessing, exploratory data analysis (EDA), feature engineering, model training, and evaluation. The models are trained on a dataset of customer information and used to predict whether a customer will churn (Attrited) or stay (Existing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Purpose**\n",
    "The primary goal of this project is to predict customer churn for a company using historical customer data. By identifying which customers are likely to churn, the company can take preventative actions, thus improving customer retention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166b9eff",
   "metadata": {},
   "source": [
    "## **Features within the dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Technologies Used**\n",
    "- **Python** 3.x\n",
    "- **Libraries**:\n",
    "  - `Pandas`: Data manipulation and analysis\n",
    "  - `Numpy`: Numerical operations\n",
    "  - `Matplotlib`, `Seaborn`: Data visualization\n",
    "  - `Scikit-learn`: Machine learning algorithms and evaluation metrics\n",
    "  - `XGBoost`: Gradient Boosting classifier for churn prediction\n",
    "  - `Imbalanced-learn`: SMOTE (Synthetic Minority Over-sampling Technique) for handling class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Steps Involved**\n",
    "### **1. Data Loading and Preprocessing**\n",
    "- Data is loaded and inspected to check for missing values and outliers.\n",
    "- Features are selected based on their relevance to the prediction.\n",
    "- Categorical variables are encoded using one-hot encoding.\n",
    "- **SMOTE** is used for handling class imbalance by oversampling the minority class (Attrited customers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Exploratory Data Analysis (EDA)**\n",
    "- Descriptive statistics are generated for numerical and categorical features.\n",
    "- Visualizations such as histograms, box plots, and heatmaps are created to analyze the distribution of features and correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Model Training**\n",
    "- **Random Forest**: Trained using the default and class-weight-balanced strategies before applying SMOTE.\n",
    "- **XGBoost**: Hyperparameter tuning is performed using **GridSearchCV** to find the best model configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Model Evaluation**\n",
    "- The models are evaluated using key metrics: Accuracy, Precision, Recall, F1 Score, Confusion Matrix, and Classification Report.\n",
    "- **Confusion Matrix** and **Classification Report** visualizations are generated for better understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Model Performance Comparison**\n",
    "- A bar plot is used to compare the performance of Random Forest and XGBoost on key metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Directory Structure**\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Results and Visualizations**\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Will add later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusion**\n",
    "This project demonstrates the process of building, training, and evaluating churn prediction models using **Random Forest** and **XGBoost** classifiers.\n",
    "With the addition of **SMOTE** for class balancing, the models are tuned to handle imbalanced datasets effectively.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Future Work**\n",
    "- Incorporate other machine learning algorithms like and **Neural Networks** for comparison.\n",
    "- Integrate the model into a real-time prediction system for customer retention.\n",
    "- Make an interactive Dashboard for the client that pings when a new customer is likely to churn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **License**\n",
    "This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
